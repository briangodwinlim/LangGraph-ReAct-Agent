{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "373c0454",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth: Will patch your computer to enable 2x faster free finetuning.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 16:07:38.485958: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1748416058.509916 2529908 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1748416058.517213 2529908 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1748416058.536627 2529908 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748416058.536659 2529908 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748416058.536661 2529908 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1748416058.536663 2529908 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-05-28 16:07:38.543374: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ¦¥ Unsloth Zoo will now patch everything to make training faster!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import mlflow\n",
    "import datetime as dt\n",
    "from torchinfo import summary\n",
    "from unsloth import FastModel\n",
    "from datasets import load_dataset\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "from unsloth import is_bfloat16_supported\n",
    "from unsloth.chat_templates import get_chat_template, standardize_data_formats, train_on_responses_only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d0a4c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Quadro RTX 6000. Num GPUs = 1. Max memory: 23.638 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Will map <|im_end|> to EOS = <|im_end|>.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Making `model.base_model.model.model` require gradients\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "==========================================================================================\n",
       "Layer (type:depth-idx)                                            Param #\n",
       "==========================================================================================\n",
       "PeftModelForCausalLM                                              --\n",
       "â”œâ”€LoraModel: 1-1                                                  --\n",
       "â”‚    â””â”€Qwen3ForCausalLM: 2-1                                      --\n",
       "â”‚    â”‚    â””â”€Qwen3Model: 3-1                                       --\n",
       "â”‚    â”‚    â”‚    â””â”€Embedding: 4-1                                   (311,164,928)\n",
       "â”‚    â”‚    â”‚    â””â”€ModuleList: 4-2                                  --\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-1                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-2                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-3                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-4                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-5                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-6                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-7                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-8                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-9                      50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-10                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-11                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-12                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-13                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-14                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-15                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-16                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-17                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-18                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-19                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-20                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-21                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-22                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-23                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-24                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-25                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-26                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-27                     50,647,296\n",
       "â”‚    â”‚    â”‚    â”‚    â””â”€Qwen3DecoderLayer: 5-28                     50,647,296\n",
       "â”‚    â”‚    â”‚    â””â”€Qwen3RMSNorm: 4-3                                (2,048)\n",
       "â”‚    â”‚    â”‚    â””â”€Qwen3RotaryEmbedding: 4-4                        --\n",
       "â”‚    â”‚    â””â”€Linear: 3-2                                           (311,164,928)\n",
       "==========================================================================================\n",
       "Total params: 2,040,456,192\n",
       "Trainable params: 8,716,288\n",
       "Non-trainable params: 2,031,739,904\n",
       "=========================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and process model + tokenizer\n",
    "model, tokenizer = FastModel.from_pretrained(\n",
    "    model_name='unsloth/Qwen3-1.7B',\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float32,\n",
    "    load_in_4bit=False,\n",
    "    load_in_8bit=False,\n",
    "    full_finetuning=False,\n",
    "    use_gradient_checkpointing='unsloth',\n",
    "    fullgraph=True,\n",
    "    unsloth_force_compile=False,\n",
    ")\n",
    "\n",
    "tokenizer = get_chat_template(\n",
    "    tokenizer=tokenizer,\n",
    "    chat_template='chatml',\n",
    "    system_message=None,\n",
    ")\n",
    "\n",
    "model = FastModel.get_peft_model(\n",
    "    model=model,\n",
    "    r=8,\n",
    "    target_modules=['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj'],\n",
    "    lora_alpha=8,\n",
    "    lora_dropout=0,\n",
    "    bias='none',\n",
    "    finetune_vision_layers=False,\n",
    "    finetune_language_layers=True,\n",
    "    finetune_attention_modules=True,\n",
    "    finetune_mlp_modules=True,\n",
    "    use_gradient_checkpointing=True,\n",
    "    random_state=3407,\n",
    "    use_rslora=False,\n",
    "    task_type='CAUSAL_LM',\n",
    ")\n",
    "\n",
    "summary(model, depth=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82bdebc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "Give three types of computer graphics.<|im_end|>\n",
      "<|im_start|>assistant\n",
      "1. Raster Graphics: These are also called bitmap graphics and are composed of pixels arranged in a grid. Each pixel can have a different color and shade. Raster graphics excel at representing photographic images and digital painting.\n",
      "\n",
      "2. Vector Graphics: These graphics are constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons. They are resolution-independent, meaning they can be scaled up or down in size without losing quality. Vector graphics are commonly used for logos, icons, typography and illustrations.\n",
      "\n",
      "3. 3D Graphics: These graphics are used to create three-dimensional digital representations of objects. 3D graphics use techniques like modeling, rendering, and shading to simulate depth and surface properties. These graphics are used in animation, video games, architecture, engineering, and virtual reality.<|im_end|>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Prepare dataset for SFT\n",
    "def format_prompts(examples):\n",
    "   texts = tokenizer.apply_chat_template(examples['conversations'], tokenize=False, add_generation_prompt=False, enable_thinking=False)\n",
    "   return {'text': texts}\n",
    "\n",
    "dataset = load_dataset('mlabonne/FineTome-100k', split='train').shuffle(seed=42).select(range(1000))\n",
    "dataset = standardize_data_formats(dataset=dataset, tokenizer=tokenizer)\n",
    "dataset = dataset.map(format_prompts, batched=True)\n",
    "print(dataset[0]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0f64b98",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/05/28 16:08:04 INFO mlflow.tracking.fluent: Experiment with name 'Model Training @ 2025-05-28 16-08-04' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Raster Graphics: These are also called bitmap graphics and are composed of pixels arranged in a grid. Each pixel can have a different color and shade. Raster graphics excel at representing photographic images and digital painting.\n",
      "\n",
      "2. Vector Graphics: These graphics are constructed using mathematical formulas representing geometric shapes like lines, curves, and polygons. They are resolution-independent, meaning they can be scaled up or down in size without losing quality. Vector graphics are commonly used for logos, icons, typography and illustrations.\n",
      "\n",
      "3. 3D Graphics: These graphics are used to create three-dimensional digital representations of objects. 3D graphics use techniques like modeling, rendering, and shading to simulate depth and surface properties. These graphics are used in animation, video games, architecture, engineering, and virtual reality.<|im_end|>\n",
      "\n",
      "GPU = Quadro RTX 6000. Max memory = 23.638 GB.\n",
      "7.639 GB of memory reserved.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs used = 1\n",
      "   \\\\   /|    Num examples = 1,000 | Num Epochs = 1 | Total steps = 30\n",
      "O^O/ \\_/ \\    Batch size per device = 2 | Gradient accumulation steps = 4\n",
      "\\        /    Data Parallel GPUs = 1 | Total batch size (2 x 4 x 1) = 8\n",
      " \"-____-\"     Trainable parameters = 8,716,288/1,729,291,264 (0.50% trained)\n",
      "`use_cache=True` is incompatible with gradient checkpointing. Setting `use_cache=False`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Will smartly offload gradients to save VRAM!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='30' max='30' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [30/30 03:17, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.545600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.966900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1.278200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1.483800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>1.472500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>1.127700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>1.523200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>1.010300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>1.109700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>1.122400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.132200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.859200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.095700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>1.293200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.735300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.982500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>1.089400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>1.208800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.098900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.020100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>0.876100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.189200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.237400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.724700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>0.996100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>0.974800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>0.679200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.748800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.750800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak reserved memory = 11.518 GB.\n",
      "Peak reserved memory for training = 3.879 GB.\n",
      "Peak reserved memory % of max memory = 48.727 %.\n",
      "Peak reserved memory for training % of max memory = 16.41 %.\n",
      "Found HuggingFace hub cache directory: /home/blim/.cache/huggingface/hub\n",
      "Checking cache directory for required files...\n",
      "Successfully copied all 1 files from cache to lora_model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth: Merging weights into 16bit: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:22<00:00, 22.79s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth: Updating system package directories\n",
      "Unsloth: All commands will now use admin permissions (sudo)\n",
      "Unsloth: Install GGUF and other packages\n",
      "Unsloth GGUF:hf-to-gguf:Loading model: lora_model\n",
      "Unsloth GGUF:hf-to-gguf:Model architecture: Qwen3ForCausalLM\n",
      "Unsloth GGUF:gguf.gguf_writer:gguf: This GGUF file is for Little Endian only\n",
      "Unsloth GGUF:hf-to-gguf:Exporting model...\n",
      "Unsloth GGUF:hf-to-gguf:gguf: loading model part 'model.safetensors'\n",
      "Unsloth GGUF:hf-to-gguf:token_embd.weight,         torch.bfloat16 --> F16, shape = {2048, 151936}\n",
      "Unsloth GGUF:hf-to-gguf:output_norm.weight,        torch.bfloat16 --> F32, shape = {2048}\n",
      "Unsloth GGUF:hf-to-gguf:Set meta model\n",
      "Unsloth GGUF:hf-to-gguf:Set model parameters\n",
      "Unsloth GGUF:hf-to-gguf:gguf: context length = 40960\n",
      "Unsloth GGUF:hf-to-gguf:gguf: embedding length = 2048\n",
      "Unsloth GGUF:hf-to-gguf:gguf: feed forward length = 6144\n",
      "Unsloth GGUF:hf-to-gguf:gguf: head count = 16\n",
      "Unsloth GGUF:hf-to-gguf:gguf: key-value head count = 8\n",
      "Unsloth GGUF:hf-to-gguf:gguf: rope theta = 1000000\n",
      "Unsloth GGUF:hf-to-gguf:gguf: rms norm epsilon = 1e-06\n",
      "Unsloth GGUF:hf-to-gguf:gguf: file type = 1\n",
      "Unsloth GGUF:hf-to-gguf:Set model quantization version\n",
      "Unsloth GGUF:hf-to-gguf:Set model tokenizer\n",
      "Unsloth GGUF:gguf.vocab:Adding 151387 merge(s).\n",
      "Unsloth GGUF:gguf.vocab:Setting special token type eos to 151645\n",
      "Unsloth GGUF:gguf.vocab:Setting special token type pad to 151654\n",
      "Unsloth GGUF:gguf.vocab:Setting chat_template to {% for message in messages %}{% if message['role'] == 'user' %}{{'<|im_start|>user\n",
      "' + message['content'] + '<|im_end|>\n",
      "'}}{% elif message['role'] == 'assistant' %}{{'<|im_start|>assistant\n",
      "' + message['content'] + '<|im_end|>\n",
      "' }}{% else %}{{ '<|im_start|>system\n",
      "' + message['content'] + '<|im_end|>\n",
      "' }}{% endif %}{% endfor %}{% if add_generation_prompt %}{{ '<|im_start|>assistant\n",
      "' }}{% endif %}\n",
      "..... Chat template truncated .....\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b0060d643c9468ba472e758313161e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Unsloth: GGUF conversion:   0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unsloth GGUF:hf-to-gguf:Model successfully exported to ./\n",
      "Unsloth: Converted to lora_model.F16.gguf with size = 3.4G\n",
      "Unsloth: Successfully saved GGUF to:\n",
      "lora_model.F16.gguf\n",
      "run `ollama create sft_model -f lora_model/Modelfile`\n"
     ]
    }
   ],
   "source": [
    "run_name = 'SFT_Run'\n",
    "output_dir = 'lora_model'\n",
    "sft_model_name = 'sft_model'\n",
    "\n",
    "mlflow.set_experiment(f'Model Training @ {dt.datetime.now().strftime('%Y-%m-%d %H-%M-%S')}')\n",
    "with mlflow.start_run(run_name=run_name):\n",
    "    # MLFlow logging\n",
    "    mlflow.set_tag('Training Info', f'Unsloth SFT')\n",
    "    \n",
    "    with open('model_summary.txt', 'w') as f:\n",
    "        f.write(str(summary(model, depth=10)))\n",
    "    mlflow.log_artifact('model_summary.txt')\n",
    "    os.remove('model_summary.txt')\n",
    "    \n",
    "    \n",
    "    # Setup SFT trainer\n",
    "    trainer = SFTTrainer(\n",
    "        model=model,\n",
    "        train_dataset=dataset,\n",
    "        eval_dataset=None,\n",
    "        peft_config=None,\n",
    "        args=SFTConfig(\n",
    "            output_dir='./logs',\n",
    "            # eval_strategy='steps',\n",
    "            dataset_text_field='text',\n",
    "            dataset_num_proc=2,\n",
    "            per_device_train_batch_size=2,\n",
    "            per_device_eval_batch_size=2,\n",
    "            gradient_accumulation_steps=4,\n",
    "            # eval_accumulation_steps=1,\n",
    "            learning_rate=2e-4,\n",
    "            weight_decay=0.01,\n",
    "            max_grad_norm=1.0,\n",
    "            # num_train_epochs=1,\n",
    "            max_steps=30,\n",
    "            lr_scheduler_type='linear',\n",
    "            warmup_steps=5,\n",
    "            logging_steps=1,\n",
    "            seed=3407,\n",
    "            # bf16=is_bfloat16_supported(),\n",
    "            # fp16=not is_bfloat16_supported(),\n",
    "            run_name=mlflow.active_run().info.run_name,\n",
    "            optim='adamw_8bit',\n",
    "            report_to='mlflow',\n",
    "            torch_compile=False,\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    trainer = train_on_responses_only(\n",
    "        trainer=trainer,\n",
    "        instruction_part='<|im_start|>user\\n',\n",
    "        response_part='<|im_start|>assistant\\n',\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "    print(tokenizer.decode([tokenizer.pad_token_id if x == -100 else x for x in trainer.train_dataset[0]['labels']]).replace(tokenizer.pad_token, ''))\n",
    "    \n",
    "    \n",
    "    # Perform SFT\n",
    "    gpu_stats = torch.cuda.get_device_properties(0)\n",
    "    start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "    print(f'GPU = {gpu_stats.name}. Max memory = {max_memory} GB.')\n",
    "    print(f'{start_gpu_memory} GB of memory reserved.')\n",
    "\n",
    "    trainer_stats = trainer.train()\n",
    "\n",
    "    used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "    used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "    used_percentage = round(used_memory / max_memory * 100, 3)\n",
    "    lora_percentage = round(used_memory_for_lora / max_memory * 100, 3)\n",
    "    print(f'Peak reserved memory = {used_memory} GB.')\n",
    "    print(f'Peak reserved memory for training = {used_memory_for_lora} GB.')\n",
    "    print(f'Peak reserved memory % of max memory = {used_percentage} %.')\n",
    "    print(f'Peak reserved memory for training % of max memory = {lora_percentage} %.')\n",
    "    \n",
    "    \n",
    "    # Save finetuned model\n",
    "    def patch_config(output_dir):\n",
    "        with open(output_dir + '/config.json', 'r', encoding='utf-8') as f:\n",
    "            config_data = json.load(f)\n",
    "        \n",
    "        config_data['architectures'] = [trainer.model.base_model.model.__class__.__name__]\n",
    "        \n",
    "        with open(output_dir + '/config.json', 'w', encoding='utf-8') as f:\n",
    "            json.dump(config_data, f, indent=2)\n",
    "\n",
    "    ## Save to VLLM\n",
    "    trainer.model.save_pretrained_merged(output_dir, tokenizer, save_method='lora')\n",
    "    # trainer.model.save_pretrained_merged(output_dir, tokenizer, save_method='merged_16bit')\n",
    "    patch_config(output_dir)\n",
    "\n",
    "    ## Save to GGUF\n",
    "    gguf_files = trainer.model.save_pretrained_gguf(output_dir, quantization_type='f16')\n",
    "    os.system(f'mv {gguf_files[0]} {output_dir}')\n",
    "    with open(f'{output_dir}/Modelfile', 'w', encoding='utf-8') as f:\n",
    "        f.write(tokenizer._ollama_modelfile.replace('{__FILE_LOCATION__}', gguf_files[0]))\n",
    "    print(f'run `ollama create {sft_model_name} -f {output_dir}/Modelfile`')\n",
    "    \n",
    "    mlflow.log_artifacts(output_dir, artifact_path=sft_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "075ac816",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth 2025.5.7: Fast Qwen3 patching. Transformers: 4.51.3.\n",
      "   \\\\   /|    Quadro RTX 6000. Num GPUs = 1. Max memory: 23.638 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.7.0+cu126. CUDA: 7.5. CUDA Toolkit: 12.6. Triton: 3.3.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.30. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: QLoRA and full finetuning all not selected. Switching to 16bit LoRA.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(True, device='cuda:0')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load finetuned model\n",
    "loaded_model, loaded_tokenizer = FastModel.from_pretrained(\n",
    "    model_name=output_dir,\n",
    "    max_seq_length=2048,\n",
    "    dtype=torch.float32,\n",
    "    load_in_4bit=False,\n",
    "    load_in_8bit=False,\n",
    "    full_finetuning=False,\n",
    "    use_gradient_checkpointing='unsloth',\n",
    "    fullgraph=True,\n",
    "    unsloth_force_compile=False,\n",
    ")\n",
    "\n",
    "torch.eq(\n",
    "    (trainer.model.base_model.model.model.layers[3].self_attn.q_proj.base_layer.weight +\n",
    "     trainer.model.base_model.model.model.layers[3].self_attn.q_proj.lora_B['default'].weight @\n",
    "     trainer.model.base_model.model.model.layers[3].self_attn.q_proj.lora_A['default'].weight),\n",
    "    loaded_model.model.layers[3].self_attn.q_proj.weight\n",
    ").all()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
