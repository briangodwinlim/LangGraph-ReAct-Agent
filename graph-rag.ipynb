{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from langchain_core.prompts.prompt import PromptTemplate\n",
    "from langchain_ollama import ChatOllama, OllamaEmbeddings\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_neo4j import Neo4jGraph, Neo4jVector, GraphCypherQAChain\n",
    "from langchain_experimental.graph_transformers import LLMGraphTransformer\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09026930",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load models\n",
    "llm = ChatOllama(model=os.getenv('OLLAMA_DEFAULT_LLM', 'gemma3:4b'), base_url=os.getenv('OLLAMA_BASE_URL'))\n",
    "embedding = OllamaEmbeddings(model=os.getenv('OLLAMA_DEFAULT_EMBEDDING', 'nomic-embed-text'), base_url=os.getenv('OLLAMA_BASE_URL'))\n",
    "\n",
    "# Load Neo4j instance\n",
    "graph = Neo4jGraph(\n",
    "    url='bolt://localhost:7687',\n",
    "    username='neo4j',\n",
    "    password='none',\n",
    "    database='neo4j',\n",
    "    timeout=None,\n",
    "    refresh_schema=False,\n",
    "    enhanced_schema=True,\n",
    ")\n",
    "\n",
    "# Load LLMGraphTransformer\n",
    "additional_instructions = \"\"\"\n",
    "Make sure to comply with the following requirements:\n",
    "- For each node, provide a `description` based only on the provided inputs.\n",
    "- For each edge, use concise relationship types with symmetric relationships having bidirectional edges.\n",
    "\"\"\"\n",
    "\n",
    "llm_transformer = LLMGraphTransformer(\n",
    "    llm=llm,\n",
    "    allowed_nodes=[],\n",
    "    allowed_relationships=[],\n",
    "    prompt=None,\n",
    "    node_properties=True,\n",
    "    relationship_properties=True,\n",
    "    additional_instructions=additional_instructions,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c23945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample text\n",
    "text = \"\"\"\n",
    "Marie Curie, born in 1867, was a Polish and naturalised-French physicist and chemist who conducted pioneering research on radioactivity.\n",
    "Marie Curie was the first woman to win a Nobel Prize, the first person to win a Nobel Prize twice, and the only person to win a Nobel Prize in two scientific fields.\n",
    "Marie Curie's husband, Pierre Curie, was a co-winner of her first Nobel Prize, making them the first-ever married couple to win the Nobel Prize and launching the Curie family legacy of five Nobel Prizes.\n",
    "Marie Curie was, in 1906, the first woman to become a professor at the University of Paris.\n",
    "\"\"\"\n",
    "\n",
    "# Load and chunk documents\n",
    "text_splitter = RecursiveCharacterTextSplitter(separators=['. ', '\\n'], chunk_size=150, chunk_overlap=20)\n",
    "documents = text_splitter.create_documents(texts=[text])\n",
    "\n",
    "# Transform documents to Knowledge Graph\n",
    "graph_documents = llm_transformer.convert_to_graph_documents(documents=documents)\n",
    "graph.add_graph_documents(graph_documents=graph_documents, include_source=True, baseEntityLabel=True)\n",
    "graph.refresh_schema()  # Refresh schema for retrieval below\n",
    "\n",
    "# Create a vector store for documents\n",
    "vector_store = Neo4jVector.from_existing_graph(\n",
    "    graph=graph,\n",
    "    embedding=embedding,\n",
    "    node_label='Document',\n",
    "    embedding_node_property='embedding',\n",
    "    text_node_properties=['text'],\n",
    "    # keyword_index_name='keyword',\n",
    "    index_name='document_index',\n",
    "    # search_type='hybrid',\n",
    ")\n",
    "vector_store.retrieval_query = vector_store.retrieval_query.replace('id: Null, ', '')    # Include node id as metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5109640",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new GraphCypherQAChain chain...\u001b[0m\n",
      "Generated Cypher:\n",
      "\u001b[32;1m\u001b[1;3mMATCH (d:Document {id: 'ac98d0e62702d7056d7e6b8c8ce22388'})-[:MENTIONS]->(p:Person {id: 'Marie Curie'})-[:MARRIED_TO]->(h:Person)\n",
      "RETURN h.id AS Husband\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'query': 'Use document ac98d0e62702d7056d7e6b8c8ce22388 as context. Who is the husband of Marie Curie?',\n",
       " 'result': [{'Husband': 'Pierre Curie'}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create retriever\n",
    "retriever = vector_store.as_retriever(search_type='similarity', search_kwargs={'k': 1})\n",
    "\n",
    "# Create GraphCypher retriever\n",
    "cypher_prompt = \"\"\"\n",
    "Task: Generate Cypher statement to query a graph database.\n",
    "\n",
    "Instructions:\n",
    "- Use only the provided relationship types and properties in the schema.\n",
    "- Do not use any other relationship types or properties that are not provided.\n",
    "\n",
    "Schema:\n",
    "{schema}\n",
    "\n",
    "Notes: \n",
    "- Do not include any explanations or apologies in your responses.\n",
    "- Do not respond to any questions that might ask anything else than for you to construct a Cypher statement.\n",
    "- Do not include any text except the generated Cypher statement.\n",
    "\n",
    "Question:\n",
    "{question}\n",
    "\"\"\"\n",
    "\n",
    "graph_retriever = GraphCypherQAChain.from_llm(\n",
    "    top_k=1,\n",
    "    llm=llm,\n",
    "    graph=graph,\n",
    "    cypher_prompt=PromptTemplate.from_template(cypher_prompt),\n",
    "    cypher_llm=llm,\n",
    "    # exclude_types=[],\n",
    "    # include_types=[],\n",
    "    validate_cypher=True,\n",
    "    allow_dangerous_requests=True,\n",
    "    verbose=True,\n",
    "    return_direct=True,\n",
    "    # use_function_response=True,\n",
    "    # return_intermediate_steps=True,\n",
    ")\n",
    "\n",
    "# Sample query\n",
    "query = 'Who is the husband of Marie Curie?'\n",
    "source_id = retriever.invoke(query)[0].metadata.get('id')\n",
    "graph_query = f'Use document {source_id} as context. {query}'\n",
    "graph_retriever.invoke({'query': graph_query})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
